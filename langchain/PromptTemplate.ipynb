{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+OvWezftgfMvcwfDx5oU0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjdzliu/ai_lab/blob/main/langchain/PromptTemplate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 两种Prompt模板封装的方式\n",
        "- PromptTemplate\n",
        "- ChatPromptTemplate"
      ],
      "metadata": {
        "id": "i4JE0OZSMqLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 --quiet install langchain openai"
      ],
      "metadata": {
        "id": "1gv6beaVAqsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "apikey=userdata.get('OPENAI_API_KEY')\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain import LLMChain"
      ],
      "metadata": {
        "id": "sUIrBxhnASKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.9,openai_api_key=apikey)  # default model_name=\"gpt-3.5-turbo-instruct\"\n",
        "#check the llm object parameters\n",
        "#print(llm)"
      ],
      "metadata": {
        "id": "D23iuJlxe9Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple without PromptTemplate\n",
        "\n"
      ],
      "metadata": {
        "id": "YJ4Ia2q6fYTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
        "print(llm.invoke(text))"
      ],
      "metadata": {
        "id": "FKGtpjWpAdJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters with PromptTemplate"
      ],
      "metadata": {
        "id": "6IwaxZ5ktL-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "I want you to act as a naming consultant for new companies.\n",
        "What is a good name for a company that makes {product} ?\n",
        "Where can customer buy these in {country_name}?\n",
        "\"\"\"\n",
        "prompt_single = PromptTemplate(\n",
        "    input_variables=[\"product\",\"country_name\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "prompt_str=prompt_single.format(product=\"colorful socks\",country_name=\"china\")"
      ],
      "metadata": {
        "id": "zlPvYRrOdvg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(prompt_str)"
      ],
      "metadata": {
        "id": "E__rCoMYtcbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## multiple parameters with PromptTemplate and chain\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tdWchH4rfepu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt_template = \"Tell me a {parameter_1} and {parameter_2} joke\"\n",
        "\n",
        "#Init a prompt object\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"parameter_1\",\"parameter_2\"], template=prompt_template\n",
        ")"
      ],
      "metadata": {
        "id": "Q0rrm2ahF7Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ],
      "metadata": {
        "id": "peYlWsgzGCfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke({\"parameter_1\":\"chinese\",\"parameter_2\":\"fashion\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DKh5B6f6jpq",
        "outputId": "cba0e11e-5d5b-4b53-b076-a2336a8f54b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'parameter_1': 'chinese',\n",
              " 'parameter_2': 'fashion',\n",
              " 'text': '\\n\\nWhy was the fashion designer feeling overwhelmed while working on a Chinese-inspired collection?\\n\\nBecause he had too many silks to sew on!'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 对话 ChatPromptTemplate example 1\n",
        "可以基于历史做回答"
      ],
      "metadata": {
        "id": "AE0yOP3Lcv2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import SystemMessagePromptTemplate,HumanMessagePromptTemplate,AIMessagePromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "Ce1HoycEcxXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(openai_api_key=apikey)"
      ],
      "metadata": {
        "id": "JNdEed7R_PDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "     SystemMessagePromptTemplate.from_template(\"这里是家用机器人展会，你在一家大型公司的展台，你是产品设计经理,你叫马克\"),\n",
        "     HumanMessagePromptTemplate.from_template(\"我发现你非常熟悉{product},我很感兴趣\"),\n",
        "     AIMessagePromptTemplate.from_template(\"很高兴认识你，我是很专业的产品专家\"),\n",
        "     HumanMessagePromptTemplate.from_template(\"我怎么称呼你,{query}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "prompt=template.format_messages(\n",
        "    product=\"打扫、做饭一体机器人\",\n",
        "    name=\"马克\",\n",
        "    query=\"你可以给我介绍一下吗\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1NaWYRZBlifq",
        "outputId": "1a91d03e-7f9a-4a4c-f95f-d5780c0e9353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'?\\nAI: 谢谢，你可以叫我马克。我可以给你介绍一下我们公司的家用机器人产品，它拥有智能识别能力，可以打扫、做饭、洗衣等家务，让你的生活更加轻松。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 对话 ChatPromptTemplate example 2"
      ],
      "metadata": {
        "id": "z8i1FDcHPI8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_2 = ChatPromptTemplate.from_messages([\n",
        "                    (\"system\", \"You are a my workmate. Your name is {name}.\"),\n",
        "                    (\"human\", \"Hello, {name}, how are you?\"),\n",
        "                    (\"ai\", \"I'm doing well, thanks! I am going to the park, If you have anything, you better ask asap\"),\n",
        "                    (\"human\", \"That's good to hear,{query}\"),\n",
        "])"
      ],
      "metadata": {
        "id": "Pboj1ah2_L9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2=template_2.format_messages(\n",
        "    name=\"jack\",\n",
        "    query=\"Have you done your work?\"\n",
        ")\n",
        "llm.invoke(prompt_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5Z-qqvyZ_SoD",
        "outputId": "28447a3c-ff29-4763-babc-68ab6e643742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\nAI: Yes, I have finished my work for the day. How about you, have you finished your tasks?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}