{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsXrpFxzqc5xk1ZrQndc4S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjdzliu/ai_lab/blob/main/langchain/PromptTemplate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 两种Prompt模板封装的方式\n",
        "- PromptTemplate\n",
        "- ChatPromptTemplate"
      ],
      "metadata": {
        "id": "i4JE0OZSMqLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 --quiet install langchain  langchain-openai"
      ],
      "metadata": {
        "id": "1gv6beaVAqsj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "apikey=userdata.get('OPENAI_API_KEY')\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain import LLMChain"
      ],
      "metadata": {
        "id": "sUIrBxhnASKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.9,openai_api_key=apikey)  # default model_name=\"gpt-3.5-turbo-instruct\"\n",
        "#check the llm object parameters\n",
        "#print(llm)"
      ],
      "metadata": {
        "id": "D23iuJlxe9Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple without PromptTemplate\n",
        "\n"
      ],
      "metadata": {
        "id": "YJ4Ia2q6fYTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
        "print(llm.invoke(text))"
      ],
      "metadata": {
        "id": "FKGtpjWpAdJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters with PromptTemplate"
      ],
      "metadata": {
        "id": "6IwaxZ5ktL-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "I want you to act as a naming consultant for new companies.\n",
        "What is a good name for a company that makes {product} ?\n",
        "Where can customer buy these in {country_name}?\n",
        "\"\"\"\n",
        "prompt_single = PromptTemplate(\n",
        "    input_variables=[\"product\",\"country_name\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "prompt_str=prompt_single.format(product=\"colorful socks\",country_name=\"china\")"
      ],
      "metadata": {
        "id": "zlPvYRrOdvg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(prompt_str)"
      ],
      "metadata": {
        "id": "E__rCoMYtcbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## multiple parameters with PromptTemplate and chain\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tdWchH4rfepu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt_template = \"Tell me a {parameter_1} and {parameter_2} joke\"\n",
        "\n",
        "#Init a prompt object\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"parameter_1\",\"parameter_2\"], template=prompt_template\n",
        ")"
      ],
      "metadata": {
        "id": "Q0rrm2ahF7Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ],
      "metadata": {
        "id": "peYlWsgzGCfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke({\"parameter_1\":\"chinese\",\"parameter_2\":\"fashion\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DKh5B6f6jpq",
        "outputId": "cba0e11e-5d5b-4b53-b076-a2336a8f54b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'parameter_1': 'chinese',\n",
              " 'parameter_2': 'fashion',\n",
              " 'text': '\\n\\nWhy was the fashion designer feeling overwhelmed while working on a Chinese-inspired collection?\\n\\nBecause he had too many silks to sew on!'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ChatOpenAI"
      ],
      "metadata": {
        "id": "v5Wy2uDJvxdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4\",openai_api_key=apikey) # 默认是gpt-3.5-turbo\n",
        "response = llm.invoke(\"你是谁\")\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnzuJA1zwrl8",
        "outputId": "74bc26c0-ed48-49dd-f6e1-3f3678ad11c8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "我是OpenAI的人工智能助手。我可以帮助解答问题、提供信息和完成各种任务。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(\n",
        "        content=\"You are a helpful assistant that translates English to French.\"\n",
        "    ),\n",
        "    HumanMessage(\n",
        "        content=\"Translate this sentence from English to French. I love programming.\"\n",
        "    ),\n",
        "]\n",
        "llm(messages)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eLEmXflvwyk",
        "outputId": "eaaae19e-023e-4462-dbcd-1710938a42d0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"J'aime la programmation.\")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 对话 ChatPromptTemplate example 1\n",
        "可以基于历史做回答"
      ],
      "metadata": {
        "id": "AE0yOP3Lcv2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import SystemMessagePromptTemplate,HumanMessagePromptTemplate,AIMessagePromptTemplate\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "Ce1HoycEcxXE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(openai_api_key=apikey)"
      ],
      "metadata": {
        "id": "JNdEed7R_PDa"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "     SystemMessagePromptTemplate.from_template(\"这里是家用机器人展会，你在一家大型公司的展台，你是产品设计经理,你叫马克\"),\n",
        "     HumanMessagePromptTemplate.from_template(\"我发现你非常熟悉{product},我很感兴趣\"),\n",
        "     AIMessagePromptTemplate.from_template(\"很高兴认识你，我是很专业的产品专家\"),\n",
        "     HumanMessagePromptTemplate.from_template(\"我怎么称呼你,{query}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "prompt=template.format_messages(\n",
        "    product=\"打扫、做饭一体机器人\",\n",
        "    name=\"马克\",\n",
        "    query=\"你可以给我介绍一下吗\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NaWYRZBlifq",
        "outputId": "1c22a6ab-7d88-43d6-8b12-d1b7b0bfda66"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='当然可以！你可以称呼我为马克先生。我是这家公司的产品设计经理，负责打扫、做饭一体机器人的设计和开发。我们的一体机器人旨在为家庭提供便利，让您的生活更加轻松和舒适。它能够完成日常的打扫和做饭任务，帮助您节省时间和精力。我们的机器人采用先进的人工智能技术和高质量的材料，确保提供卓越的性能和耐用性。如果您对我们的产品感兴趣，我可以为您提供更详细的信息和演示。')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 对话 ChatPromptTemplate example 2"
      ],
      "metadata": {
        "id": "z8i1FDcHPI8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_2 = ChatPromptTemplate.from_messages([\n",
        "                    (\"system\", \"You are a my workmate. Your name is {name}.\"),\n",
        "                    (\"human\", \"Hello, {name}, how are you?\"),\n",
        "                    (\"ai\", \"I'm doing well, thanks! I am going to the park, If you have anything, you better ask asap\"),\n",
        "                    (\"human\", \"That's good to hear,{query}\"),\n",
        "])"
      ],
      "metadata": {
        "id": "Pboj1ah2_L9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2=template_2.format_messages(\n",
        "    name=\"jack\",\n",
        "    query=\"Have you done your work?\"\n",
        ")\n",
        "llm.invoke(prompt_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5Z-qqvyZ_SoD",
        "outputId": "28447a3c-ff29-4763-babc-68ab6e643742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\nAI: Yes, I have finished my work for the day. How about you, have you finished your tasks?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}