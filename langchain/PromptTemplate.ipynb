{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDzLTw+iK85zdXQiKE/f3d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjdzliu/ai_lab/blob/main/langchain/PromptTemplate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 两种Prompt模板封装的方式\n",
        "- PromptTemplate\n",
        "- ChatPromptTemplate"
      ],
      "metadata": {
        "id": "i4JE0OZSMqLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 --quiet install langchain  langchain-openai"
      ],
      "metadata": {
        "id": "1gv6beaVAqsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "apikey=userdata.get('OPENAI_API_KEY')\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "sUIrBxhnASKj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.9,openai_api_key=apikey)  # default model_name=\"gpt-3.5-turbo-instruct\"\n",
        "#check the llm object parameters\n",
        "#print(llm)"
      ],
      "metadata": {
        "id": "D23iuJlxe9Ab"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple without PromptTemplate\n",
        "\n"
      ],
      "metadata": {
        "id": "YJ4Ia2q6fYTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
        "print(llm.invoke(text))"
      ],
      "metadata": {
        "id": "FKGtpjWpAdJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Directly put template in PromptTemplate.\n",
        "### Instantiation using from_template (recommended)"
      ],
      "metadata": {
        "id": "oYi4lp0n1Pom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = PromptTemplate.from_template(\"tell me a joke about  {subject} \")\n",
        "print(\"===Template===\")\n",
        "print(template)\n",
        "print(\"===Prompt===\")\n",
        "print(template.format(subject='sun'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrvvoMFK1ZEV",
        "outputId": "cb8f1197-a5e4-4213-f7a0-74f3fb86942d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===Template===\n",
            "input_variables=['subject'] template='tell me a joke about  {subject} '\n",
            "===Prompt===\n",
            "tell me a joke about  sun \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_prompt=template.format(subject='sun')\n",
        "ret = llm.invoke(simple_prompt)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "wkLMyyjI1xI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters with PromptTemplate\n",
        "###  Instantiation using initializer"
      ],
      "metadata": {
        "id": "6IwaxZ5ktL-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "I want you to act as a naming consultant for new companies.\n",
        "What is a good name for a company that makes {product} ?\n",
        "Where can customer buy these in {country_name}?\n",
        "\"\"\"\n",
        "prompt_single = PromptTemplate(\n",
        "    input_variables=[\"product\",\"country_name\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "prompt_str=prompt_single.format(product=\"colorful socks\",country_name=\"china\")"
      ],
      "metadata": {
        "id": "zlPvYRrOdvg2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(prompt_str)"
      ],
      "metadata": {
        "id": "E__rCoMYtcbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## multiple parameters with PromptTemplate and chain\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tdWchH4rfepu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt_template = \"Tell me a {parameter_1} and {parameter_2} joke\"\n",
        "\n",
        "#Init a prompt object\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"parameter_1\",\"parameter_2\"], template=prompt_template\n",
        ")"
      ],
      "metadata": {
        "id": "Q0rrm2ahF7Q4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ],
      "metadata": {
        "id": "peYlWsgzGCfi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke({\"parameter_1\":\"chinese\",\"parameter_2\":\"fashion\"})"
      ],
      "metadata": {
        "id": "7DKh5B6f6jpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23296e5c-ed34-42f4-d112-50030f4e23c2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'parameter_1': 'chinese',\n",
              " 'parameter_2': 'fashion',\n",
              " 'text': '\\n\\nWhy was the Chinese fashion designer always so successful?\\n\\nBecause he knew how to make a statement with his seams.'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ChatOpenAI"
      ],
      "metadata": {
        "id": "v5Wy2uDJvxdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "tnzuJA1zwrl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4\",openai_api_key=apikey) # 默认是gpt-3.5-turbo\n",
        "response = llm.invoke(\"你是谁\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "X-AXKRP948Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Simple example without parameters\n",
        "messages = [\n",
        "    SystemMessage(\n",
        "        content=\"You are a helpful assistant that translates English to French.\"\n",
        "    ),\n",
        "    HumanMessage(\n",
        "        content=\"Translate this sentence from English to French. I love programming.\"\n",
        "    ),\n",
        "]\n",
        "llm(messages)\n"
      ],
      "metadata": {
        "id": "0eLEmXflvwyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 对话 ChatPromptTemplate example 1\n",
        "可以基于历史做回答"
      ],
      "metadata": {
        "id": "AE0yOP3Lcv2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import SystemMessagePromptTemplate,HumanMessagePromptTemplate,AIMessagePromptTemplate\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "Ce1HoycEcxXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(openai_api_key=apikey)"
      ],
      "metadata": {
        "id": "JNdEed7R_PDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Example with parameters\n",
        "template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "     SystemMessagePromptTemplate.from_template(\"这里是家用机器人展会，你在一家大型公司的展台，你是产品设计经理,你叫马克\"),\n",
        "     HumanMessagePromptTemplate.from_template(\"我发现你非常熟悉{product},我很感兴趣\"),\n",
        "     AIMessagePromptTemplate.from_template(\"很高兴认识你，我是很专业的产品专家\"),\n",
        "     HumanMessagePromptTemplate.from_template(\"我怎么称呼你,{query}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "prompt=template.format_messages(\n",
        "    product=\"打扫、做饭一体机器人\",\n",
        "    name=\"马克\",\n",
        "    query=\"你可以给我介绍一下吗\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "1NaWYRZBlifq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 对话 ChatPromptTemplate example 2"
      ],
      "metadata": {
        "id": "z8i1FDcHPI8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_2 = ChatPromptTemplate.from_messages([\n",
        "                    (\"system\", \"You are a my workmate. Your name is {name}.\"),\n",
        "                    (\"human\", \"Hello, {name}, how are you?\"),\n",
        "                    (\"ai\", \"I'm doing well, thanks! I am going to the park, If you have anything, you better ask asap\"),\n",
        "                    (\"human\", \"That's good to hear,{query}\"),\n",
        "])"
      ],
      "metadata": {
        "id": "Pboj1ah2_L9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2=template_2.format_messages(\n",
        "    name=\"jack\",\n",
        "    query=\"Have you done your work?\"\n",
        ")\n",
        "llm.invoke(prompt_2)"
      ],
      "metadata": {
        "id": "5Z-qqvyZ_SoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save and Load prompt example\n",
        "保存格式 JSON\n"
      ],
      "metadata": {
        "id": "K0807NAehR0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init a simple template\n",
        "single_input_prompt = PromptTemplate(input_variables = ['product'],\n",
        "                                template = 'What is a good name for a company that makes {product}?, Directly tell me name')"
      ],
      "metadata": {
        "id": "4dQVio7ph6Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"typle is\",type(single_input_prompt),\"\\n\",\"content is: \",single_input_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjlU8hclhWQA",
        "outputId": "67ec8a8c-a9d8-4f24-da7e-38d7c430807c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "typle is <class 'langchain_core.prompts.prompt.PromptTemplate'> \n",
            " content is:  input_variables=['product'] template='What is a good name for a company that makes {product}?, Directly tell me name'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "single_input_prompt.save(\"Saved_prompt.json\")"
      ],
      "metadata": {
        "id": "q9BkZ7QxibkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"Saved_prompt.json\") as file:\n",
        "  file_content = file.read()\n",
        "  print(  file_content )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADRwHBBQkhvr",
        "outputId": "da15d8a2-1fb9-426f-eb70-6052af3f75e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": null,\n",
            "    \"input_variables\": [\n",
            "        \"product\"\n",
            "    ],\n",
            "    \"input_types\": {},\n",
            "    \"output_parser\": null,\n",
            "    \"partial_variables\": {},\n",
            "    \"metadata\": null,\n",
            "    \"tags\": null,\n",
            "    \"template\": \"What is a good name for a company that makes {product}?, Directly tell me name\",\n",
            "    \"template_format\": \"f-string\",\n",
            "    \"validate_template\": false,\n",
            "    \"_type\": \"prompt\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import load_prompt\n",
        "\n",
        "loaded_prompt = load_prompt(\"Saved_prompt.json\")"
      ],
      "metadata": {
        "id": "jpNqy0driiSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Method-1 format tempalte with format() is:\n",
        "loaded_prompt.format(product='colorful socks')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2IdyN-SJivSL",
        "outputId": "f3c2ab17-473d-41f5-b19d-4173381923a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is a good name for a company that makes colorful socks?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Method-2 format tempalte with partial() is:\n",
        "kv={\"product\":'smart house robot'}\n",
        "final_prompt=loaded_prompt.partial(**kv)\n",
        "\n",
        "print(final_prompt.format())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKzxTXRjSqoF",
        "outputId": "d2f134b9-4b81-438f-8497-35d2d33e3e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is a good name for a company that makes smart house robot?, Directly tell me name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(final_prompt.format())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZvUeLbICjEIo",
        "outputId": "c4645f17-c405-48f5-d0d0-a65b0d6deb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\"SmartBots Inc.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}